# Phase 1 Configuration
# Add to backend/.env or core/config.py

# LLM Queue Settings
LLM_QUEUE_ENABLED=true
LLM_QUEUE_WORKERS=2  # Number of dedicated LLM workers

# Resource Limits
MAX_WORKER_MEMORY_MB=4096  # 4GB per worker
MAX_WORKER_MEMORY_PERCENT=80.0  # 80% of available memory
MAX_WORKER_CPU_PERCENT=90.0  # 90% CPU usage

# Job Timeouts
EXTRACTION_JOB_TIMEOUT_SECONDS=300  # 5 minutes per extraction job
LLM_TASK_TIMEOUT_SECONDS=120  # 2 minutes per LLM task
OCR_PAGE_TIMEOUT_SECONDS=30  # 30 seconds per page

# OCR Batching
OCR_BATCH_SIZE=5  # Process 5 pages at a time
OCR_MAX_WORKERS=2  # Number of OCR workers

# Monitoring
ENABLE_RESOURCE_MONITORING=true
RESOURCE_MONITOR_INTERVAL_SECONDS=60  # Log metrics every 60s
